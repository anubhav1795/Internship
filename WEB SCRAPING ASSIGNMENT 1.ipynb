#!/usr/bin/env python
# coding: utf-8

# **1) Write a python program to display all the header tags from wikipedia.org.**
# 
# 

# In[30]:


# 1Write a python program to display all the header tags from wikipedia.org.
import requests
from bs4 import BeautifulSoup

# scraping a wikipedia article
url_link = 'https://en.wikipedia.org/wiki/Main_Page'
request = requests.get(url_link)

Soup = BeautifulSoup(request.text, 'lxml')

# creating a list of all common heading tags 
heading_tags = ['h1','h2','h3','h4','h5','h6','h7']
for tags in Soup.find_all(heading_tags):
    print(tags.name + '-->'+ tags.text.strip() )


# In[ ]:





#  

# **2) Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. name, rating, year 
# of release) and make data frame.**

# In[11]:


# importing the required liabraries 
from bs4 import BeautifulSoup
import requests
import re 
import pandas as pd

#Downloading the imdb top rated 100 movie's data
url_link = 'https://www.imdb.com/list/ls091520106/'
response = requests.get(url_link)
soup = BeautifulSoup(response.text,"html.parser")
soup





# In[13]:


# creating empty lists to store the data\
names = []
years = []
ratings = []

#movie items
movie_items = soup.find_all('div',class_='lister-item-content')

# iterating over each movie
for movie in movie_items:
    #name
    name =  movie.find('a').text.strip()
    names.append(name)
    
    #ratings
    rating = movie.find('span', class_='ipl-rating-star__rating').text.strip()
    ratings.append(float(rating))
    
    #year of realease
    year= movie.find('span',class_='lister-item-year').text.strip()
    years.append(year)
    
# creating dataframe 
df = pd.DataFrame({'Names':names, 'Rating': ratings, 'Year of Release':years})

print(df)


# In[ ]:







# **3) Write a python program to scrape mentioned details from dineout.co.in : i) Restaurant name 
# ii) Cuisine iii) Location iv) Ratings v) Image URL.**
# 
# 

# In[14]:


import requests
from bs4 import BeautifulSoup

url_link= 'https://www.dineout.co.in/delhi-restaurants/buffet-special'

page = requests.get(url_link)
page




# In[15]:


soup = BeautifulSoup(page.content)
soup


# In[18]:


first_title = soup.find('div',class_='restnt-info cursor')
first_title.text


# In[20]:


titles = []
for i in soup.find_all('div',class_ ="restnt-info cursor"):
    titles.append(i.text)
location = []
for i in soup.find_all('div',class_="restnt-loc ellipsis"):
    location.append(i.text)
    
location

ratings = []
for i in soup.find_all('div',class_="restnt-rating rating-4"):
    ratings.append(i.text)
    
ratings

detail_info_cuisine_accomodation   = []
for i in soup.find_all('span',class_="double-line-ellipsis"):
    detail_info_cuisine_accomodation .append(i.text)
    
detail_info_cuisine_accomodation 


images = []
for i in soup.find_all('img',class_="no-img"):
    images.append(i['data-src'])
print(len(titles),len(location),len(ratings),len(images))
import pandas as pd
df = pd.DataFrame({'Titles':titles,'Location':location,'Ratings':ratings,'Images':images})
df


# 
# 
# 
# 

# **4) Write s python program to display list of respected former finance minister of India(i.e. 
# Name , Term of office) from https://presidentofindia.nic.in/former-presidents and make 
# data frame**

# In[29]:


import requests
from bs4 import BeautifulSoup

url_link= 'https://presidentofindia.nic.in/former-presidents'

page = requests.get(url_link)
page

soup = BeautifulSoup(page.content)
soup
#initilazating empty list to store 
names=[]
terms=[]
president_items =soup.find_all('div',class_="president-listing")

#data extracting for each president
for president in president_items:
    
    name = president.find('h3').text.strip()
    names.append(name)

    term_of_office = president.find('h5').text.strip()
    terms.append(term_of_office)

import pandas as pd
df = pd.DataFrame({'Name of the President':names,'Term ':terms})
df


# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:




